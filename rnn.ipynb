{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network for Google Stock Price\n",
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preprocessing\n",
    "### Importing the training set\n",
    "\n",
    "Here, we are specifically importing and utilizing the training set in this analysis to highlight the fact that our model will be trained solely on this data. During the training phase, our model will have no knowledge of the test set, and there will be no equivalent of the test set available during training. Essentially, it's as if the test set doesn't exist for our model during the training process.\n",
    "\n",
    "However, once the training is completed, we will introduce the test set to assess and validate the model's performance by making predictions on future stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('./data/Google_Stock_Price_Train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Open    High     Low   Close      Volume\n",
       "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Date      0\n",
      "Open      0\n",
      "High      0\n",
      "Low       0\n",
      "Close     0\n",
      "Volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = dataset_train.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have any missing values.\n",
    "\n",
    "Now we define the real data input for our model (training set) by selecting the necessary column (Open) and converting them into a NumPy array, which will serve as the input data for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset_train[['Open']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Now, we are going to apply the appropriate feature scaling to our data to optimize the training process.\n",
    "\n",
    "We have two possibilities:\n",
    "- Standardization\n",
    "- Normalization\n",
    "\n",
    "I have chosen to use Normalization as it is more relevant in this context. When building an RNN, especially when a sigmoid function is used as an activation function in the output layer, it is recommended to apply normalization for improved performance.\n",
    "\n",
    "Normalization helps in bringing all features to a similar scale, which can aid in the training process by ensuring that no particular feature dominates due to its larger scale. This is particularly important for activation functions like sigmoid, where small input values can result in vanishing gradients, impacting learning during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_scaled = scaler.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08581368]\n",
      " [0.09701243]\n",
      " [0.09433366]\n",
      " ...\n",
      " [0.95725128]\n",
      " [0.93796041]\n",
      " [0.93688146]]\n"
     ]
    }
   ],
   "source": [
    "print(training_set_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a specific data structure\n",
    "Now, we will define a specific data structure that outlines what the RNN needs to remember when predicting the next stock price. This structure is referred to as the 'number of time steps.' It plays a critical role in determining the temporal memory or context the RNN will consider during its prediction of future stock prices.\n",
    "\n",
    "In this case, we have 60 timesteps and one output. This implies that at each time 't,' the RNN will analyze the 60 stock prices leading up to time 't' (or the 60 days prior to time 't'), and then we will attempt to predict the subsequent output.\n",
    "\n",
    "X_train: The input for the RNN, consisting of the 60 previous stock prices.\n",
    "y_train: The output representing the stock price for the next financial day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "nb_timesteps = 60\n",
    "\n",
    "for i in range(nb_timesteps, len(training_set_scaled)):\n",
    "    X_train.append(training_set_scaled[i-nb_timesteps:i, 0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08581368 0.09701243 0.09433366 ... 0.07846566 0.08034452 0.08497656]\n",
      " [0.09701243 0.09433366 0.09156187 ... 0.08034452 0.08497656 0.08627874]\n",
      " [0.09433366 0.09156187 0.07984225 ... 0.08497656 0.08627874 0.08471612]\n",
      " ...\n",
      " [0.92106928 0.92438053 0.93048218 ... 0.95475854 0.95204256 0.95163331]\n",
      " [0.92438053 0.93048218 0.9299055  ... 0.95204256 0.95163331 0.95725128]\n",
      " [0.93048218 0.9299055  0.93113327 ... 0.95163331 0.95725128 0.93796041]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08627874 0.08471612 0.07454052 ... 0.95725128 0.93796041 0.93688146]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping \n",
    "We are now going to reshape the data structure to introduce additional dimensions to the previous data structure, allowing for the inclusion of more indicators if desired.\n",
    "\n",
    "The input shape with Keras should be a 3D tensor with dimensions (batch_size, timesteps, input_dim) for Recurrent Layers. 'Batch_size' corresponds to the number of observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, timesteps = X_train.shape\n",
    "input_dim = 1\n",
    "\n",
    "X_train = np.reshape(X_train, (batch_size, timesteps, input_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the right structure expected for our RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Building the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Making the predictions and visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
